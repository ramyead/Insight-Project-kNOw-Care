{
    "collab_server" : "",
    "contents" : "pacman::p_load(stringr, ggplot2, car, effects, lme4, lmerTest, dplyr, reshape2, tidyr, sjPlot, \n               nlme, mlr, parallelMap)\n\nload(\"Data/care.final.rda\")\nload(\"Data/hai.final.rda\")\nload(\"Data/readmission.rda\")\nload(\"Data/reimbursement.rda\")\nload(\"Data/care_info.rda\")\n#options(warn=0)\ndattot = inner_join(read.final, reimbursement.final) %>% inner_join(hai.final) %>% inner_join(care.final)\n\n#save(dattot, file = \"Data/dattot.rda\")\n\n# mod = lm(MORT_30_HF ~ H_CLEAN_STAR_RATING   +   H_COMP_1_STAR_RATING    + \n#            H_COMP_2_STAR_RATING   +  H_COMP_3_STAR_RATING  +   H_COMP_4_STAR_RATING  +   H_COMP_5_STAR_RATING    +\n#            H_COMP_6_STAR_RATING   + H_COMP_7_STAR_RATING   +  H_HSP_RATING_STAR_RATING + H_QUIET_STAR_RATING  + \n#            H_RECMND_STAR_RATING    + H_STAR_RATING + State, dattot)\n# anova(mod)\n# plot(allEffects(mod), multiline = T)\n\n#hist(dattot$READM_30_HF)\n\nthresh = quantile(filter(dattot, READM_30_HF != 0)$READM_30_HF, c(.70))  ## 70th percentile of readmission rate and above\nthresh2 = sd(filter(dattot, READM_30_HF != 0)$READM_30_HF) + mean(filter(dattot, READM_30_HF != 0)$READM_30_HF)\nthresh = 23 # Bad readmission rate is 23% or higher\n\n\nggplot(data= filter(dattot,READM_30_HF != 0), aes(READM_30_HF)) + geom_histogram(breaks=seq(0, 60, by = .1), \n col=\"green\",    fill=\"blue\",  alpha = .2) + \n  labs(x=\"Readmission Rate\", y=\"Count\") + xlim(c(15,30)) + geom_vline(xintercept = thresh) + theme_bw()\n\ndat2 = filter(dattot, READM_30_HF != 0) %>% mutate(outcome = as.factor(ifelse(READM_30_HF > thresh, \"bad\", \"normal\")))\nggplot(dat2, aes(outcome, ..count..)) + geom_bar(aes(fill = outcome), position = \"dodge\") + theme_bw(base_size = 24)\n\n# modlog = glm(outcome ~ H_CLEAN_STAR_RATING   +   H_COMP_1_STAR_RATING    + \n#       H_COMP_2_STAR_RATING   +  H_COMP_3_STAR_RATING  +   H_COMP_4_STAR_RATING  +   H_COMP_5_STAR_RATING    +\n#       H_COMP_6_STAR_RATING   + H_COMP_7_STAR_RATING   +  H_HSP_RATING_STAR_RATING + H_QUIET_STAR_RATING  + \n#       H_RECMND_STAR_RATING    + H_STAR_RATING + State, data = dat2, family = \"binomial\")\n# \n# Anova(modlog)\n# plot(allEffects(modlog), multiline = T)\n\n# modlog = glm(outcome ~ H_COMP_2_STAR_RATING, data = dat2, family = \"binomial\")\n# Anova(modlog)\n# plot(allEffects(modlog), multiline = T)\n# plot(H_COMP_6_STAR_RATING ~ outcome, dat2)\n\n###LEARNER\n# dattest = ungroup(dat2) %>% select(outcome, H_CLEAN_STAR_RATING, H_COMP_1_STAR_RATING, \n#                  H_COMP_2_STAR_RATING,  H_COMP_3_STAR_RATING,   H_COMP_4_STAR_RATING,   H_COMP_5_STAR_RATING,\n#                  H_COMP_6_STAR_RATING, H_COMP_7_STAR_RATING,  H_HSP_RATING_STAR_RATING, H_QUIET_STAR_RATING, \n#                 H_RECMND_STAR_RATING, H_STAR_RATING) %>% data.frame()\n#write.csv(dattest, file = \"Data/mldat.csv\")\n\ndattest2 = ungroup(dat2) %>% select(outcome, H_CLEAN_STAR_RATING, H_COMP_1_STAR_RATING, \n   H_COMP_2_STAR_RATING,  H_COMP_3_STAR_RATING,   H_COMP_4_STAR_RATING,   H_COMP_5_STAR_RATING,\n   H_COMP_6_STAR_RATING, H_COMP_7_STAR_RATING, H_QUIET_STAR_RATING) %>% data.frame()\n\n#save(dattest2, file =  \"Data/mldat.rda\")\n\ntask = makeClassifTask(data = dattest2, target = \"outcome\", positive = 'bad')\n#task = normalizeFeatures(task)\nmeas <- list(bac, mlr::auc, tpr, tnr)\n\ngetWeight <- function(task){\n  x <- table(getTaskData(task, target.extra = T)$target)\n  max(x)/min(x)\n}\n\ninner <- makeResampleDesc(\"RepCV\", folds = 10, reps = 2, stratify = T)\nouter <- makeResampleDesc(\"RepCV\", folds = 10, reps = 2,  stratify = T)\nctrl <- makeTuneControlGrid(resolution = 10)\n\n### Ridge\nlrn <- makeLearner(\"classif.LiblineaRL2LogReg\", predict.type = \"prob\")\nweight.wrap <- makeWeightedClassesWrapper(lrn, wcw.param = 'wi', wcw.weight =  getWeight(task))\nps <- makeParamSet(makeNumericParam(\"cost\",lower = 0.01, upper = 10))\ntune.wrap <- makeTuneWrapper(weight.wrap, inner, par.set = ps, control = ctrl, measures = auc)\n\n### KSVM\n# lrn <- makeLearner(\"classif.ksvm\", class.weights = getWeight(task))\n# getParamSet(lrn)\n# weight.wrap <- makeWeightedClassesWrapper(lrn, class.weights = getWeight(task))\n# ps <- makeParamSet(makeNumericParam(\"nu\",lower = 0, upper = 5))\n# tune.wrap <- makeTuneWrapper(lrn, inner, par.set = ps, control = ctrl, measures = bac)\n\nparallelStartSocket(6)\nout <- resample(tune.wrap, task, outer, measures = meas, extract = getTuneResult)\nparallelStop()\n\nperf = out$measures.test %>% gather() %>% filter(key != \"iter\") %>% group_by(key) %>% \n  summarise(mean(value)) %>% rename(Measure = key, Accuracy = `mean(value)`)\n\nprint(perf)\n#save(perf, file = \"Data/lasso perf.rda\")\nggplot(perf, aes(x = Measure, y = Accuracy, fill = Measure)) + geom_bar(stat=\"identity\") + \n  coord_cartesian(ylim = c(0.50, .70))  + theme_bw(base_size = 18)\n\nout$extract\nw = getWeight(task)\nw\nlrn = makeLearner(\"classif.LiblineaRL2LogReg\", predict.type = \"prob\", \n                                 cost = 10, wi = c(bad = w, normal = 1))\n#outt <- resample(lrn, task, outer, measures = meas)\n\ngetHyperPars(lrn)\nmod = train(lrn, task)\npred = as.data.frame(predict(mod, newdata = dattest2[1:500, 2:ncol(dattest2)]))\ntable(pred$response)\n\n#### Get Variable Significance\nopt.weight.wrap <- makeWeightedClassesWrapper(lrn, wcw.param = 'wi', wcw.weight = w)\nsigni.var = train(opt.weight.wrap, task)$learner.model$next.model$learner.model$W\nsig.var = as.data.frame(signi.var) %>% select(-Bias) %>% mutate_all(funs(as.numeric)) \ncolnames(sig.var) = c(\"Cleanliness\", \"Nurse interaction\", \"Doctors interaction\", \"Staff interaction\", \"Pain management\",\n\"Medication info\", \"Discharge info\", \"Care transition\", \"Quietness\")\nsig.var = gather(sig.var) %>% arrange(desc(abs(value))) %>% mutate(key = as.factor(key)) %>% tbl_df()\n\nggplot(sig.var, aes(x = key, y = value, fill = key)) + geom_bar(stat=\"identity\") + theme_bw(base_size = 16.5) +\n  xlab(\"Measure\") + ylab(\"Contribution in prediction model\")\n\n#save(sig.var, file = \"Data/sig.var.rda\")\nsig.var1 = sig.var\n\ntheTable <- within(sig.var1, key <- factor(key,  levels=names(sort(table(key), decreasing=TRUE))))\n\nggplot(theTable, aes(x = reorder(key, -abs(value)), y = value, fill = key)) + geom_bar(stat=\"identity\") + \n  theme_bw(base_size = 16.8) + xlab(\"Measure\") + ylab(\"Contribution in prediction model\") \n\n\n\n\n\n\n\n\n\n",
    "created" : 1496958056176.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3596083673",
    "id" : "B06A9FD4",
    "lastKnownWriteTime" : 1497989198,
    "last_content_update" : 1497989198835,
    "path" : "C:/Users/ramye/OneDrive/Active Projects/Insight/Scripts/Modelling Complications as a binary predictor.R",
    "project_path" : "Scripts/Modelling Complications as a binary predictor.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}